{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview  \n",
    "  \n",
    "The **AzureOpenAI-ResearchPaperAnalyzer** project is designed to facilitate the analysis of research papers using the powerful capabilities of Azure OpenAI. The primary objective of this project is to automate the extraction and categorization of key insights from research papers written in markdown format. By leveraging Azure OpenAI's advanced natural language processing abilities, the script can:  \n",
    "  \n",
    "- Process markdown files of research papers.  \n",
    "- Extract key insights and bullet points from the text.  \n",
    "- Categorize the extracted information according to different research fields, funding sources, and affiliations.  \n",
    "- Generate a summary of the paper's content and structure.  \n",
    "- Format and save the results into a CSV file for easy analysis and reporting.  \n",
    "  \n",
    "This tool aims to save researchers significant time and effort by automating the tedious process of reading and summarizing lengthy research papers, allowing them to focus more on the critical aspects of their work.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import Markdown, display, Image\n",
    "\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name = \"gpt-4o-mini\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "\n",
    "\n",
    "api_version = \"2024-02-15-preview\"  # This seems to work\n",
    "\n",
    "#print the environment variables\n",
    "print(\"Azure OpenAI API Key: \", api_key)\n",
    "print(\"Azure OpenAI Endpoint: \", azure_endpoint)\n",
    "print(\"Azure OpenAI API Version: \", api_version)\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=api_key,  \n",
    "  azure_endpoint=azure_endpoint,\n",
    "  api_version=api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=deployment_name,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": \"Hello! Could you solve 2+2?\"}  # <-- This is the user message for which the model will generate a response\n",
    "  ]\n",
    ")\n",
    "  \n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the article file from the markdown folder\n",
    "article_files = glob.glob(\"*.md\")\n",
    "\n",
    "#lets limit the files to first 5 for now\n",
    "article_files = article_files[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets chunk the transcript into smaller parts and we want to include the last sentence of the previous chunk in the next chunk to ensure that the context is maintained.\n",
    "\n",
    "#we will use the split_text function to split the text into smaller parts\n",
    "def split_text(text, limit):\n",
    "    \"\"\"\n",
    "    Split the text into smaller parts that are less than the limit\n",
    "    \"\"\"\n",
    "    text_parts = []\n",
    "    current_part = \"\"\n",
    "    current_length = 0\n",
    "    for sentence in text.split(\".\"):\n",
    "        if current_length + len(sentence) < limit:\n",
    "            current_part += sentence + \".\"\n",
    "            current_length += len(sentence)\n",
    "        else:\n",
    "            text_parts.append(current_part)\n",
    "            current_part = sentence + \".\"\n",
    "            current_length = len(sentence)\n",
    "    text_parts.append(current_part)\n",
    "    return text_parts\n",
    "\n",
    "\n",
    "#lets split the full transcript into smaller parts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_system_message = {\"role\": \"system\", \"content\": \"You are an AI assistant that helps with creating bullet points of long research papers. you will be given chunks of the research paper. From the eyes of a experienced researcher you will check the chunk and then using condensed bullet points encapsulate the key points of the paper without extraneous details. We need to use this to determine the Field Of Research Code, any Funding sources, and any affiliaitons to La Trobe university so meticulous attention to detail is required.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each article file in the markdown folder call the function to load the data into a variable\n",
    "\n",
    "for article_file in article_files:\n",
    "    with open(article_file, 'r', encoding=\"utf-8\") as file:\n",
    "        article = file.read()\n",
    "        chunk_size = 8000\n",
    "        article_length = len(article)\n",
    "        chunks = article_length//chunk_size\n",
    "        print(f\"The article {article_file} is {article_length} tokens long and will be split into {chunks} chunks.\")\n",
    "        text_parts = split_text(article, chunk_size)\n",
    "        print(f\"Transcript split into {len(text_parts)} parts.\")\n",
    "        #setup the notes.md file using the format file name + notes.md\n",
    "        notes_file = article_file.replace(\".md\", \"_notes.md\")\n",
    "        with open(notes_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(\"# Notes\\n\\n\")\n",
    "            for i, text_part in enumerate(text_parts):\n",
    "                print(f\"Processing part {i+1}/{len(text_parts)}\")\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=deployment_name,\n",
    "                    messages=[first_system_message, {\"role\": \"user\", \"content\": text_part}]\n",
    "                )\n",
    "                response = completion.choices[0].message.content\n",
    "                file.write(f\"## Part {i+1}\\n\\n\")\n",
    "                file.write(f\"{response}\\n\\n\")\n",
    "                #print(response)\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets run three system prompts across each of the _notes.md files to get the final output\n",
    "\n",
    "#load the article file from the markdown folder\n",
    "article_notes = glob.glob(\"*_notes.md\")\n",
    "\n",
    "#lets limit the files to first 2 for now\n",
    "article_notes = article_notes[:5]\n",
    "\n",
    "article_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_of_research_code_system_prompt = {\"role\": \"system\", \"content\": \"\"\"You are an expert in the Australian and New Zealand Standard Research Classification (ANZSRC) system, specifically the Fields of Research (FoR) codes. Your task is to analyze detailed notes about a research paper and identify the most appropriate **4-digit Fields of Research (FoR) code** based on the study's focus, methodology, subject matter, and key findings.  \n",
    "  \n",
    "The notes may be divided into multiple parts (e.g., Part 1, Part 2, etc.), but they all pertain to the same research paper. Treat all parts as a single cohesive input and use the entire set of notes to determine the primary field of research.  \n",
    "  \n",
    "The ANZSRC FoR classification system is hierarchical:  \n",
    "1. **2-digit codes** represent broad research divisions (e.g., 11 Medical and Health Sciences).  \n",
    "2. **4-digit codes** represent specific research groups within the divisions (e.g., 1106 Human Movement and Sports Science).  \n",
    "3. **6-digit codes** provide even finer granularity but are not required for this task.  \n",
    "  \n",
    "Your task is to:  \n",
    "1. Focus on the **4-digit code** level to classify the research into its most relevant research group.  \n",
    "2. Analyze all parts of the notes provided, including the studyâ€™s focus, keywords, methodology, findings, and implications, to determine the research discipline.  \n",
    "3. Prioritize the **primary field of research** rather than secondary or interdisciplinary areas, even if the study spans multiple fields.  \n",
    "  \n",
    "### Guidance for Identifying the Correct 4-Digit FoR Code:  \n",
    "- Consider the **research focus**: What is the primary subject or discipline of the study? (e.g., sports performance, biomechanics, environmental science).  \n",
    "- Look for **methodology and tools**: What scientific methods, techniques, or tools were used? (e.g., statistical parametric mapping, biomechanical analysis).  \n",
    "- Refer to **keywords and findings**: What are the main themes or keywords associated with the research? (e.g., para-biathlon, pacing strategies, skiing performance).  \n",
    "- Contextualize the **discipline**: Think about which academic field the study's content aligns with most closely.  \n",
    "  \n",
    "If the research overlaps multiple disciplines, choose the **primary discipline** that best represents the core focus of the study. Use the content, keywords, and context provided in the notes to guide your classification.  \n",
    "  \n",
    "### Examples:  \n",
    "Input: \"This research examines the biomechanics of elite swimmers to improve stroke efficiency.\"  \n",
    "Output: \"1106\"  \n",
    "  \n",
    "Input: \"This study investigates the impact of social media algorithms on user behavior and engagement.\"  \n",
    "Output: \"0806\"  \n",
    "  \n",
    "Input: \"This paper analyzes the genetic basis of drought resistance in wheat using genome-wide association studies.\"  \n",
    "Output: \"0604\"  \n",
    "  \n",
    "### Analyze the following notes (divided into multiple parts) and provide the **4-digit Fields of Research (FoR) code**:  \n",
    "\"\"\" } # Update prompt for FOR Code detection here if needed\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_sources_system_prompt = {\"role\": \"system\", \"content\": \"\"\"You are an expert research assistant tasked with identifying funding sources for academic studies. Your job is to analyze detailed notes about a research paper, which may be divided into multiple parts but pertains to a single study. Your goal is to extract all mentions of funding sources or statements indicating the lack of funding from the notes.  \n",
    "  \n",
    "Carefully review all parts of the notes as a single cohesive input and provide one of the following outputs:  \n",
    "1. A list of funding sources mentioned in the notes, including grant names, funding agencies, organizations, or any other details related to funding.  \n",
    "2. If no funding information is mentioned in the notes, explicitly state: \"No funding sources were reported in the provided notes.\"  \n",
    "  \n",
    "### Examples:  \n",
    "Input:  \n",
    "\"The research was funded by the European Research Council (ERC Starting Grant 6789). Additional funding was provided by the Swedish Research Council.\"  \n",
    "Output:  \n",
    "\"Funding Sources: European Research Council (ERC Starting Grant 6789), Swedish Research Council.\"  \n",
    "  \n",
    "Input:  \n",
    "\"The authors declared no funding sources for this research. Ethical approval was obtained from the university ethics committee.\"  \n",
    "Output:  \n",
    "\"No funding sources were reported in the provided notes.\"  \n",
    "  \n",
    "Input:  \n",
    "\"The study acknowledges financial support from the National Institutes of Health (NIH grant R01-AB123456).\"  \n",
    "Output:  \n",
    "\"Funding Sources: National Institutes of Health (NIH grant R01-AB123456).\"  \n",
    "  \n",
    "Now, analyze the following notes and extract all funding-related information:  .\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university = \"La Trobe University\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"\"\"You are an expert research assistant tasked with identifying affiliations to a specific university in academic research. Your job is to analyze detailed notes about a research paper, which may be divided into multiple parts but pertains to a single study. The university name will be provided as a placeholder `{university}`, and you must check if any authors or affiliations mentioned in the notes are explicitly connected to this university.  \n",
    "  \n",
    "Carefully review all parts of the notes as a single cohesive input and provide one of the following outputs:  \n",
    "1. If any author or affiliation is explicitly linked to `{university}`, list the relevant details (e.g., author name, department, or any specific mention of the university).  \n",
    "2. If no affiliation to `{university}` is mentioned in the notes, explicitly state: \"No affiliations to {university} were reported in the provided notes.\"  \n",
    "  \n",
    "### Guidelines:  \n",
    "- Look for explicit mentions of `{university}` in any part of the notes, including author affiliations, acknowledgments, or other sections.  \n",
    "- Treat the notes as a single cohesive input, even if they are divided into multiple parts.  \n",
    "- Only report affiliations explicitly linked to `{university}`. Do not infer or assume affiliations based on other universities or organizations.  \n",
    "  \n",
    "### Examples:  \n",
    "Input:  \n",
    "\"University: La Trobe University    \n",
    "Notes:    \n",
    "- Authors: Dr. John Smith (La Trobe University, Department of Sports Science), Dr. Jane Doe (University of Melbourne).    \n",
    "- Acknowledgments: The authors thank La Trobe University for providing access to research facilities.\"  \n",
    "Output:  \n",
    "\"Affiliations to La Trobe University: Dr. John Smith (Department of Sports Science), acknowledgment of research facilities.\"  \n",
    "  \n",
    "Input:  \n",
    "\"university: La Trobe University    \n",
    "Notes:    \n",
    "- Authors: Dr. Emily Brown (University of Sydney), Dr. Mark Wilson (Monash University).    \n",
    "- No mention of La Trobe University in the acknowledgments or affiliations.\"  \n",
    "Output:  \n",
    "\"No affiliations to La Trobe University were reported in the provided notes.\"  \n",
    "  \n",
    "Input:  \n",
    "\"university: University of Sydney    \n",
    "Notes:    \n",
    "- Authors: Dr. Alex Green (University of Sydney, Faculty of Medicine), Dr. Lisa White (University of Queensland).    \n",
    "- The study was supported by the University of Sydney research grant.\"  \n",
    "Output:  \n",
    "\"Affiliations to University of Sydney: Dr. Alex Green (Faculty of Medicine), research grant support.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation_system_prompt = {\"role\": \"system\", \"content\": content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_friendly_format_system_prompt = {\"role\": \"system\", \"content\": \"\"\"YYou are an expert research assistant tasked with consolidating the results of multiple analyses into a structured Markdown table. Each iteration will provide the following information about a research paper:  \n",
    "1. **Title of the Paper:** The title of the research paper being analyzed.  \n",
    "2. **FoR Code Classification:** The primary Fields of Research (FoR) 4-digit code that best represents the study, along with the reasons for selecting this code.  \n",
    "3. **Funding Sources Extraction:** A list of funding sources mentioned in the notes or confirmation that no funding was reported.  \n",
    "4. **University Affiliations Extraction:** A list of affiliations to a specific university or confirmation that no affiliations were reported.  \n",
    "  \n",
    "Your task is to:  \n",
    "1. Extract the most important pieces of information from the results.  \n",
    "2. Combine this information into **a single Markdown table row**, excluding the header row and divider row, as they are already pre-generated.  \n",
    "  \n",
    "### Output Format:  \n",
    "The output must be a **Markdown-formatted row** for the table, with data separated by vertical bars (`|`). Do not include the header or divider rows. Make sure the row has the following structure:  \n",
    "| [Title] | [FoR Code] | [Reason for FoR Code] | [Funding Sources] | [Affiliations] |   \"\"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup a markdown file with the following columns Article Title, Field of Research Code, Reasoning, Funding Sources, Affiliations\n",
    "#this file will be appeneded with the results of the system prompts for each article\n",
    "\n",
    "#setup the output markdown file\n",
    "with open(\"results.md\", 'w', encoding='utf-8') as file:  \n",
    "    file.write(\"\"\"\\  \n",
    "| Title                                   | FoR Code | Reason for FoR Code                     | Funding Sources          | Affiliations to University           |  \n",
    "|-----------------------------------------|----------|-----------------------------------------|--------------------------|---------------------------------------|  \n",
    "\"\"\")\n",
    "#lets run the system prompts across each of the _notes.md files to get the final output\n",
    "\n",
    "\n",
    "for article_note in article_notes:\n",
    "    with open(article_note, 'r', encoding=\"utf-8\") as file:\n",
    "        article = file.read()\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[field_of_research_code_system_prompt, {\"role\": \"user\", \"content\": article}]\n",
    "        )\n",
    "        fieldOfResearchResult = completion.choices[0].message.content\n",
    "        print(fieldOfResearchResult)\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[funding_sources_system_prompt, {\"role\": \"user\", \"content\": article}]\n",
    "        )\n",
    "        fundingSourcesResult = completion.choices[0].message.content\n",
    "        print(fundingSourcesResult)\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[affiliation_system_prompt, {\"role\": \"user\", \"content\": article}]\n",
    "        )  \n",
    "        affiliationsResult = completion.choices[0].message.content\n",
    "        print(affiliationsResult)\n",
    "\n",
    "        #lets collate the results into a string\n",
    "        collatedResults = f\"{fieldOfResearchResult}, {fundingSourcesResult}, {affiliationsResult}\"\n",
    "\n",
    "        #lets call the completion function to get a csv friendly response for the results\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[md_friendly_format_system_prompt, {\"role\": \"user\", \"content\": collatedResults}]\n",
    "        )\n",
    "        md_friendly_format = completion.choices[0].message.content\n",
    "        #append to the markdown file results.md with the results\n",
    "        with open(\"results.md\", 'a', encoding='utf-8') as file:\n",
    "            file.write(f\"{md_friendly_format}\\n\")\n",
    "        print(md_friendly_format)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #save the response to the csv file\n",
    "        with open(\"results.csv\", 'a', encoding='utf-8') as file:\n",
    "            file.write(f\"{csv_friendly_format}\\n\")\n",
    "        \n",
    "        # #print the response\n",
    "        # print(f\"Article: {article_file}\")\n",
    "        # print(f\"Field of Research Code: {fieldOfResearchResult}\")\n",
    "        # print(f\"Funding Sources: {fundingSourcesResult}\")\n",
    "        # print(f\"Affiliations: {affiliationsResult}\")\n",
    "        # #print a new line\n",
    "        # print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
