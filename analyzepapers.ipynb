{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview  \n",
    "  \n",
    "The **AzureOpenAI-ResearchPaperAnalyzer** project is designed to facilitate the analysis of research papers using the powerful capabilities of Azure OpenAI. The primary objective of this project is to automate the extraction and categorization of key insights from research papers written in markdown format. By leveraging Azure OpenAI's advanced natural language processing abilities, the script can:  \n",
    "  \n",
    "- Process markdown files of research papers.  \n",
    "- Extract key insights and bullet points from the text.  \n",
    "- Categorize the extracted information according to different research fields, funding sources, and affiliations.  \n",
    "- Generate a summary of the paper's content and structure.  \n",
    "- Format and save the results into a CSV file for easy analysis and reporting.  \n",
    "  \n",
    "This tool aims to save researchers significant time and effort by automating the tedious process of reading and summarizing lengthy research papers, allowing them to focus more on the critical aspects of their work.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import Markdown, display, Image\n",
    "\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name = \"gpt-4o-mini\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "\n",
    "\n",
    "api_version = \"2024-02-15-preview\"  # This seems to work\n",
    "\n",
    "#print the environment variables\n",
    "print(\"Azure OpenAI API Key: \", api_key)\n",
    "print(\"Azure OpenAI Endpoint: \", azure_endpoint)\n",
    "print(\"Azure OpenAI API Version: \", api_version)\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=api_key,  \n",
    "  azure_endpoint=azure_endpoint,\n",
    "  api_version=api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=deployment_name,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": \"Hello! Could you solve 2+2?\"}  # <-- This is the user message for which the model will generate a response\n",
    "  ]\n",
    ")\n",
    "  \n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the article file from the markdown folder\n",
    "article_files = glob.glob(\"*.md\")\n",
    "\n",
    "#lets limit the files to first 5 for now\n",
    "article_files = article_files[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets chunk the transcript into smaller parts and we want to include the last sentence of the previous chunk in the next chunk to ensure that the context is maintained.\n",
    "\n",
    "#we will use the split_text function to split the text into smaller parts\n",
    "def split_text(text, limit):\n",
    "    \"\"\"\n",
    "    Split the text into smaller parts that are less than the limit\n",
    "    \"\"\"\n",
    "    text_parts = []\n",
    "    current_part = \"\"\n",
    "    current_length = 0\n",
    "    for sentence in text.split(\".\"):\n",
    "        if current_length + len(sentence) < limit:\n",
    "            current_part += sentence + \".\"\n",
    "            current_length += len(sentence)\n",
    "        else:\n",
    "            text_parts.append(current_part)\n",
    "            current_part = sentence + \".\"\n",
    "            current_length = len(sentence)\n",
    "    text_parts.append(current_part)\n",
    "    return text_parts\n",
    "\n",
    "\n",
    "#lets split the full transcript into smaller parts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_system_message = {\"role\": \"system\", \"content\": \"\"\"You are an AI assistant specializing in summarizing research papers into concise and meaningful bullet points. You will be provided with chunks of a single research paper, and your task is to analyze each chunk like an experienced researcher. Your goal is to extract and encapsulate the key points in a way that is clear, focused, and free from unnecessary details. Your summary should maintain the academic integrity of the content while being easy to understand.  \n",
    "  \n",
    "For each chunk, focus on the following aspects:  \n",
    "  \n",
    "1. **Research Focus**:   \n",
    "   - Identify the primary subject or discipline of the study.   \n",
    "   - For example: child psychology, sports performance, public health interventions, etc.  \n",
    "  \n",
    "2. **Methodology and Tools**:  \n",
    "   - Specify the scientific methods, techniques, or tools used in the research.  \n",
    "   - For example: meta-analysis, randomized controlled trials, biomechanical analysis, geospatial modeling, etc.  \n",
    "  \n",
    "3. **Keywords and Findings**:  \n",
    "   - Highlight the main themes, keywords, or notable findings associated with the study.  \n",
    "   - For example: online parenting programs, health interventions, micro-pacing strategies, etc.  \n",
    "  \n",
    "4. **Disciplinary Context**:  \n",
    "   - Determine the academic field most closely aligned with the study's content, ideally using the ANZSRC classification (if applicable).  \n",
    "   - For example: psychology, health sciences, engineering, environmental studies, etc.  \n",
    "  \n",
    "Your output should be structured as bullet points for clarity. Condense the information into concise statements without sacrificing meaning or relevance.  \n",
    "  \n",
    "---  \n",
    "  \n",
    "### Example:  \n",
    "  \n",
    "#### Input (Chunk of a Research Paper):  \n",
    "\"This study investigates the impact of online parenting programs on improving parenting practices and child outcomes. A meta-analysis was conducted on 25 studies that evaluated the effectiveness of web-based interventions for parents of children aged 3–12 years. Key findings include significant improvements in parenting confidence and reductions in child behavioral problems. The study contributes to the field of child psychology and highlights the importance of accessible digital tools for parenting support.\"  \n",
    "  \n",
    "#### Output (Bullet Points):  \n",
    "- **Research Focus**: Examines the effectiveness of online parenting programs on parenting practices and child outcomes.  \n",
    "- **Methodology and Tools**: Meta-analysis of 25 studies on web-based interventions for parents of children aged 3–12 years.  \n",
    "- **Keywords and Findings**: Parenting confidence, child behavioral problems, digital tools for parenting support.  \n",
    "- **Disciplinary Context**: Child psychology; aligns with research on digital health interventions in family contexts.  \n",
    "  \n",
    "---  \n",
    "  \n",
    "### Instructions:  \n",
    "1. Carefully review each provided chunk of the research paper.  \n",
    "2. Extract the key points based on the four outlined categories: **Research Focus**, **Methodology and Tools**, **Keywords and Findings**, and **Disciplinary Context**.  \n",
    "3. Write your output as concise, well-structured bullet points.  \n",
    "4. Avoid including extraneous details or repetitive information.      \n",
    "  \"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each article file in the markdown folder call the function to load the data into a variable\n",
    "\n",
    "for article_file in article_files:\n",
    "    with open(article_file, 'r', encoding=\"utf-8\") as file:\n",
    "        article = file.read()\n",
    "        chunk_size = 8000\n",
    "        article_length = len(article)\n",
    "        chunks = article_length//chunk_size\n",
    "        print(f\"The article {article_file} is {article_length} tokens long and will be split into {chunks} chunks.\")\n",
    "        text_parts = split_text(article, chunk_size)\n",
    "        print(f\"Transcript split into {len(text_parts)} parts.\")\n",
    "        #setup the notes.md file using the format file name + notes.md\n",
    "        notes_file = article_file.replace(\".md\", \"_notes.md\")\n",
    "        with open(notes_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(\"# Notes\\n\\n\")\n",
    "            for i, text_part in enumerate(text_parts):\n",
    "                print(f\"Processing part {i+1}/{len(text_parts)}\")\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=deployment_name,\n",
    "                    messages=[first_system_message, {\"role\": \"user\", \"content\": text_part}]\n",
    "                )\n",
    "                response = completion.choices[0].message.content\n",
    "                file.write(f\"## Part {i+1}\\n\\n\")\n",
    "                file.write(f\"{response}\\n\\n\")\n",
    "                #print(response)\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets run three system prompts across each of the _notes.md files to get the final output\n",
    "\n",
    "#load the article file from the markdown folder\n",
    "article_notes = glob.glob(\"*_notes.md\")\n",
    "\n",
    "#lets limit the files to first 2 for now\n",
    "article_notes = article_notes[:5]\n",
    "\n",
    "article_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_of_research_code_system_prompt = {\"role\": \"system\", \"content\": \"\"\"You are an expert in the **2020 Australian and New Zealand Standard Research Classification (ANZSRC)** system, specifically the **Fields of Research (FoR)** codes. Your task is to analyze the notes or description of a research paper and identify the most appropriate **4-digit Fields of Research (FoR) code** that corresponds to the subject matter of the research.    \n",
    "  \n",
    "The ANZSRC FoR classification system is hierarchical:    \n",
    "1. **2-digit codes** represent broad research divisions (e.g., 42 Health Sciences).    \n",
    "2. **4-digit codes** represent specific research groups within those divisions (e.g., 4206 Public Health).    \n",
    "3. **6-digit codes** provide even finer granularity but are not required for this task.    \n",
    "  \n",
    "## Your Task:  \n",
    "1. Focus on the **4-digit FoR code** level to classify the research into its most relevant research group.    \n",
    "2. Analyze all notes provided about the study, including its focus, methodology, subject matter, keywords, and implications, to determine the **primary field of research**.    \n",
    "3. Prioritize the **primary discipline** of the study rather than secondary or interdisciplinary areas, even if the study spans multiple fields.    \n",
    "4. Where relevant, you may also suggest **secondary FoR codes** that reflect interdisciplinary aspects of the research.  \n",
    "  \n",
    "---  \n",
    "  \n",
    "## Guidance for Identifying the Correct 4-Digit FoR Code:  \n",
    "- **Research Focus**: What is the primary subject or discipline of the study? (e.g., child psychology, sports performance, public health interventions).    \n",
    "- **Methodology and Tools**: What scientific methods, techniques, or tools were used? (e.g., meta-analysis, randomized controlled trials, biomechanical analysis).    \n",
    "- **Keywords and Findings**: What are the main themes or keywords associated with the research? (e.g., online parenting programs, health interventions, micro-pacing strategies).    \n",
    "- **Disciplinary Context**: Which academic field does the study's content align with most closely within the ANZSRC classification?    \n",
    "  \n",
    "If the research overlaps multiple disciplines, choose the **primary FoR code** that best represents the core focus of the study. Use the content, keywords, and context provided in the notes to guide your classification.  \n",
    "  \n",
    "---  \n",
    "  \n",
    "## Examples:  \n",
    "  \n",
    "### Example 1:  \n",
    "**Input**: \"This research examines the biomechanics of elite swimmers to improve stroke efficiency.\"    \n",
    "**Output**: \"4207 – Sports Science and Exercise\"    \n",
    "  \n",
    "### Example 2:  \n",
    "**Input**: \"This study investigates the impact of social media algorithms on user behavior and engagement.\"    \n",
    "**Output**: \"5205 – Communication and Media Studies\"    \n",
    "  \n",
    "### Example 3:  \n",
    "**Input**: \"This paper analyzes the genetic basis of drought resistance in wheat using genome-wide association studies.\"    \n",
    "**Output**: \"3105 – Genetics\"    \n",
    "  \n",
    "---  \n",
    "  \n",
    "### Analyze the following notes and provide the **4-digit Fields of Research (FoR) code**:  \n",
    "\"\"\" } # Update prompt for FOR Code detection here if needed\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_sources_system_prompt = {\"role\": \"system\", \"content\": \"\"\"You are an expert research assistant tasked with identifying funding sources for academic studies. Your job is to analyze detailed notes about a research paper, which may be divided into multiple parts but pertains to a single study. Your goal is to extract all mentions of funding sources or statements indicating the lack of funding from the notes.  \n",
    "  \n",
    "Carefully review all parts of the notes as a single cohesive input and provide one of the following outputs:  \n",
    "1. A list of funding sources mentioned in the notes, including grant names, funding agencies, organizations, or any other details related to funding.  \n",
    "2. If no funding information is mentioned in the notes, explicitly state: \"No funding sources were reported in the provided notes.\"  \n",
    "  \n",
    "### Examples:  \n",
    "Input:  \n",
    "\"The research was funded by the European Research Council (ERC Starting Grant 6789). Additional funding was provided by the Swedish Research Council.\"  \n",
    "Output:  \n",
    "\"Funding Sources: European Research Council (ERC Starting Grant 6789), Swedish Research Council.\"  \n",
    "  \n",
    "Input:  \n",
    "\"The authors declared no funding sources for this research. Ethical approval was obtained from the university ethics committee.\"  \n",
    "Output:  \n",
    "\"No funding sources were reported in the provided notes.\"  \n",
    "  \n",
    "Input:  \n",
    "\"The study acknowledges financial support from the National Institutes of Health (NIH grant R01-AB123456).\"  \n",
    "Output:  \n",
    "\"Funding Sources: National Institutes of Health (NIH grant R01-AB123456).\"  \n",
    "  \n",
    "Now, analyze the following notes and extract all funding-related information:  .\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university = \"La Trobe University\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"\"\"You are an expert research assistant tasked with identifying affiliations to a specific university in academic research. Your job is to analyze detailed notes about a research paper, which may be divided into multiple parts but pertains to a single study. The university name will be provided as a placeholder `{university}`, and you must check if any authors or affiliations mentioned in the notes are explicitly connected to this university.  \n",
    "  \n",
    "Carefully review all parts of the notes as a single cohesive input and provide one of the following outputs:  \n",
    "1. If any author or affiliation is explicitly linked to `{university}`, list the relevant details (e.g., author name, department, or any specific mention of the university).  \n",
    "2. If no affiliation to `{university}` is mentioned in the notes, explicitly state: \"No affiliations to {university} were reported in the provided notes.\"  \n",
    "  \n",
    "### Guidelines:  \n",
    "- Look for explicit mentions of `{university}` in any part of the notes, including author affiliations, acknowledgments, or other sections.  \n",
    "- Treat the notes as a single cohesive input, even if they are divided into multiple parts.  \n",
    "- Only report affiliations explicitly linked to `{university}`. Do not infer or assume affiliations based on other universities or organizations.  \n",
    "  \n",
    "### Examples:  \n",
    "Input:  \n",
    "\"University: La Trobe University    \n",
    "Notes:    \n",
    "- Authors: Dr. John Smith (La Trobe University, Department of Sports Science), Dr. Jane Doe (University of Melbourne).    \n",
    "- Acknowledgments: The authors thank La Trobe University for providing access to research facilities.\"  \n",
    "Output:  \n",
    "\"Affiliations to La Trobe University: Dr. John Smith (Department of Sports Science), acknowledgment of research facilities.\"  \n",
    "  \n",
    "Input:  \n",
    "\"university: La Trobe University    \n",
    "Notes:    \n",
    "- Authors: Dr. Emily Brown (University of Sydney), Dr. Mark Wilson (Monash University).    \n",
    "- No mention of La Trobe University in the acknowledgments or affiliations.\"  \n",
    "Output:  \n",
    "\"No affiliations to La Trobe University were reported in the provided notes.\"  \n",
    "  \n",
    "Input:  \n",
    "\"university: University of Sydney    \n",
    "Notes:    \n",
    "- Authors: Dr. Alex Green (University of Sydney, Faculty of Medicine), Dr. Lisa White (University of Queensland).    \n",
    "- The study was supported by the University of Sydney research grant.\"  \n",
    "Output:  \n",
    "\"Affiliations to University of Sydney: Dr. Alex Green (Faculty of Medicine), research grant support.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation_system_prompt = {\"role\": \"system\", \"content\": content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_friendly_format_system_prompt = {\"role\": \"system\", \"content\": \"\"\"YYou are an expert research assistant tasked with consolidating the results of multiple analyses into a structured Markdown table. Each iteration will provide the following information about a research paper:  \n",
    "1. **Title of the Paper:** The title of the research paper being analyzed.  \n",
    "2. **FoR Code Classification:** The primary Fields of Research (FoR) 4-digit code that best represents the study, along with the reasons for selecting this code.  \n",
    "3. **Funding Sources Extraction:** A list of funding sources mentioned in the notes or confirmation that no funding was reported.  \n",
    "4. **University Affiliations Extraction:** A list of affiliations to a specific university or confirmation that no affiliations were reported.  \n",
    "  \n",
    "Your task is to:  \n",
    "1. Extract the most important pieces of information from the results.  \n",
    "2. Combine this information into **a single Markdown table row**, excluding the header row and divider row, as they are already pre-generated.  \n",
    "  \n",
    "### Output Format:  \n",
    "The output must be a **Markdown-formatted row** for the table, with data separated by vertical bars (`|`). Do not include the header or divider rows. Make sure the row has the following structure:  \n",
    "| [Title] | [FoR Code] | [Reason for FoR Code] | [Funding Sources] | [Affiliations] |   \"\"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup a csv file with the following columns Article, Field of Research Code, Reasoning, Funding Sources, Affiliations\n",
    "#this file will be appeneded with the results of the system prompts for each article\n",
    "\n",
    "#setup the output markdown file\n",
    "with open(\"results.md\", 'w', encoding='utf-8') as file:  \n",
    "    file.write(\"\"\"\\  \n",
    "| Title                                   | FoR Code | Reason for FoR Code                     | Funding Sources          | Affiliations to University           |  \n",
    "|-----------------------------------------|----------|-----------------------------------------|--------------------------|---------------------------------------|  \n",
    "\"\"\")\n",
    "#lets run the system prompts across each of the _notes.md files to get the final output\n",
    "\n",
    "\n",
    "for article_note in article_notes:\n",
    "    with open(article_note, 'r', encoding=\"utf-8\") as file:\n",
    "        article = file.read()\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[field_of_research_code_system_prompt, {\"role\": \"user\", \"content\": article}]\n",
    "        )\n",
    "        fieldOfResearchResult = completion.choices[0].message.content\n",
    "        print(fieldOfResearchResult)\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[funding_sources_system_prompt, {\"role\": \"user\", \"content\": article}]\n",
    "        )\n",
    "        fundingSourcesResult = completion.choices[0].message.content\n",
    "        print(fundingSourcesResult)\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[affiliation_system_prompt, {\"role\": \"user\", \"content\": article}]\n",
    "        )  \n",
    "        affiliationsResult = completion.choices[0].message.content\n",
    "        print(affiliationsResult)\n",
    "\n",
    "        #lets collate the results into a string\n",
    "        collatedResults = f\"{fieldOfResearchResult}, {fundingSourcesResult}, {affiliationsResult}\"\n",
    "\n",
    "        #lets call the completion function to get a csv friendly response for the results\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[md_friendly_format_system_prompt, {\"role\": \"user\", \"content\": collatedResults}]\n",
    "        )\n",
    "        md_friendly_format = completion.choices[0].message.content\n",
    "        #append to the markdown file results.md with the results\n",
    "        with open(\"results.md\", 'a', encoding='utf-8') as file:\n",
    "            file.write(f\"{md_friendly_format}\\n\")\n",
    "        print(md_friendly_format)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        # #print the response\n",
    "        # print(f\"Article: {article_file}\")\n",
    "        # print(f\"Field of Research Code: {fieldOfResearchResult}\")\n",
    "        # print(f\"Funding Sources: {fundingSourcesResult}\")\n",
    "        # print(f\"Affiliations: {affiliationsResult}\")\n",
    "        # #print a new line\n",
    "        # print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
